[
  {
    "objectID": "P10.html#paqueter√≠a",
    "href": "P10.html#paqueter√≠a",
    "title": "10¬† Modelos lineales generalizados: Logit",
    "section": "10.1 Paqueter√≠a",
    "text": "10.1 Paqueter√≠a\n\n#install.packages(\"sjPlot\", dependencies=T) # solito porque da problmas\nlibrary(sjPlot)\n\nif (!require(\"pacman\")) install.packages(\"pacman\") # instala pacman si se requiere\n\nCargando paquete requerido: pacman\n\npacman::p_load(tidyverse, # sobretodo para dplyr\n              haven, #importaci√≥n\n              janitor, #tablas\n              sjlabelled, # etiquetas\n              DescTools, # Paquete para estimaciones y pruebas\n              infer, # tidy way \n              broom,  # Una escobita para limpiar (pero es para arreglar)\n              estimatr, car, stargazer, ggpubr, \n              jtools, lm.beta, robustbase, sandwich,\n              officer,flextable,huxtable, ggstance, kableExtra,\n               ResourceSelection, lmtest, mlogit, nnet) # Nuevos\n\nE importamos la base e incluimos los cambios anteriores\n\netiqueta_sex&lt;-c(\"Hombre\", \"Mujer\")\n\nconcentradohogar &lt;- haven::read_dta(\"datos/concentradohogar.dta\")  %&gt;% \n  mutate(sexo_jefe=as.numeric(sexo_jefe)) %&gt;% ## para quitar el \"string\"\n  sjlabelled::set_labels(sexo_jefe, labels=etiqueta_sex) %&gt;% \n  mutate(clase_hog=as.numeric(clase_hog)) %&gt;% ## para quitar el \"string\"\n  sjlabelled::set_labels(clase_hog, labels=c(\"unipersonal\",\n                                             \"nuclear\", \n                                             \"ampliado\",\n                                             \"compuesto\",\n                                             \"corresidente\")) %&gt;% \n  mutate(educa_jefe=as.numeric(educa_jefe)) %&gt;% \n  set_labels(educa_jefe,\n             labels=c(\"Sin instrucci√≥n\", \n                      \"Preescolar\",\n                      \"Primaria incompleta\",\n                      \"Primaria completa\",\n                      \"Secundaria incompleta\",\n                      \"Secundaria completa\",\n                      \"Preparatoria incompleta\",\n                      \"Preparatoria completa\",\n                      \"Profesional incompleta\",\n                      \"Profesional completa\",\n                      \"Posgrado\")) %&gt;% \n    mutate(ent=stringr::str_sub(folioviv, start=1, end=2 )) %&gt;% \n    mutate(ing_per=ing_cor/tot_integ) %&gt;% \n    mutate(recibe_rem=remesas&gt;0)\n\n\n10.1.1 Sub-setting y modelos clase anterior\nVamos a hacer una sub-base de nuestras posibles variables explicativas. Esto es importante porque s√≥lo podemos comparar modelos con la misma cantidad de observaciones.\n\nmydata&lt;- concentradohogar %&gt;% \n  select(folioviv, foliohog, tam_loc, ing_per, sexo_jefe, recibe_rem, \n         educa_jefe, edad_jefe, tot_integ, clase_hog, ent) %&gt;%  \n  mutate_at(vars(educa_jefe, sexo_jefe, clase_hog), ~ as_label(.x)) %&gt;% \n  mutate(log_ing_per=log(ing_per)) %&gt;% \n  filter(!is.infinite(log_ing_per)) %&gt;% \n  mutate(recibe_rem=as.numeric(recibe_rem))\n\n\ntail(mydata)\n\n\n\n\nfoliovivfoliohogtam_locing_persexo_jeferecibe_remeduca_jefeedad_jefetot_integclase_hogentlog_ing_per\n\n3260797706147.64e+03Hombre0Posgrado346nuclear328.94\n\n3260797907141.1e+04¬†Hombre0Secundaria completa283nuclear329.3¬†\n\n3260797908148.5e+03¬†Hombre0Secundaria incompleta523nuclear329.05\n\n3260797909146.76e+03Hombre0Primaria completa374nuclear328.82\n\n3260797910147.97e+04Hombre0Secundaria completa632nuclear3211.3¬†\n\n3260797912141.45e+04Hombre0Profesional completa293nuclear329.58"
  },
  {
    "objectID": "P10.html#introducci√≥n",
    "href": "P10.html#introducci√≥n",
    "title": "10¬† Modelos lineales generalizados: Logit",
    "section": "10.2 Introducci√≥n",
    "text": "10.2 Introducci√≥n\nEn esta pr√°ctica vamos a revisar los elementos b√°sicos para la regresi√≥n log√≠stica. El proceso en R para todos los modelos generalizados se parece mucho. Por tanto, no ser√° dif√≠cil que luego puedas utilizar otras funciones de enlace.\nVamos a hacer una sub-base de nuestras posibles variables explicativas. Esto es importante porque s√≥lo podemos comparar modelos con la misma cantidad de observaciones. Intentaremos predecir la participaci√≥n econ√≥mica"
  },
  {
    "objectID": "P10.html#regresi√≥n-log√≠stica",
    "href": "P10.html#regresi√≥n-log√≠stica",
    "title": "10¬† Modelos lineales generalizados: Logit",
    "section": "10.3 Regresi√≥n Log√≠stica",
    "text": "10.3 Regresi√≥n Log√≠stica\n\\[ ln\\frac{p(x=1)}{p(x=0)}=\\beta_o+\\beta_1x +\\epsilon\\]\n\n10.3.1 Un solo predictor\n\nmodelo0 &lt;- glm(recibe_rem ~ edad_jefe,\n               family = binomial(\"logit\"),\n               data=mydata, \n               na.action=na.exclude) # opcional\n\nsummary(modelo0)\n\n\nCall:\nglm(formula = recibe_rem ~ edad_jefe, family = binomial(\"logit\"), \n    data = mydata, na.action = na.exclude)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.2532372  0.0493028 -65.985   &lt;2e-16 ***\nedad_jefe    0.0088474  0.0008864   9.982   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 39801  on 90092  degrees of freedom\nResidual deviance: 39702  on 90091  degrees of freedom\nAIC: 39706\n\nNumber of Fisher Scoring iterations: 5\n\nconfint(modelo0)\n\nWaiting for profiling to be done...\n\n\n                   2.5 %      97.5 %\n(Intercept) -3.350156887 -3.15688294\nedad_jefe    0.007109184  0.01058387\n\n\nCon jtools:\n\nsumm(modelo0)\n\n\n\n\n\nObservations\n90093\n\n\nDependent variable\nrecibe_rem\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n\n\n\n\n\nùõò¬≤(1)\n98.97\n\n\nPseudo-R¬≤ (Cragg-Uhler)\n0.00\n\n\nPseudo-R¬≤ (McFadden)\n0.00\n\n\nAIC\n39706.33\n\n\nBIC\n39725.15\n\n\n\n\n\n\n\n\n\nEst.\nS.E.\nz val.\np\n\n\n\n\n(Intercept)\n-3.25\n0.05\n-65.98\n0.00\n\n\nedad_jefe\n0.01\n0.00\n9.98\n0.00\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.3.2 Predicci√≥n de probabilidades\nPara predecir la probabilidad, primero chequemos el rango de nuestra variabe explicativa\n\nrange(mydata$edad_jefe)\n\n[1]  13 109\n\n\nHacemos un vector con los valores que queremos predecir\n\nxedad_jefe &lt;- 12:109\n\nVamos a utilizar el comando ‚Äúpredict‚Äù para predecir los valores. Podemos el argumento ‚Äúresponse‚Äù para que nos d√© el logito\n\ny_logito &lt;- predict(modelo0, list(edad_jefe = xedad_jefe))\ny_prob&lt;- predict(modelo0, list(edad_jefe = xedad_jefe), type= \"response\")\n\nresults_m0&lt;-cbind(y_logito, y_prob, xedad_jefe)\nresults_m0&lt;-as.data.frame(results_m0)\n\nHoy podemos graficar\n\nggplot(data=results_m0, aes(x=xedad_jefe, y=y_prob)) +\n  geom_point()\n\n\n\n\n\n\n10.3.3 Coeficientes exponenciados\nPara interpretar mejor los coeficientes suelen exponenciarse y hablar de las veces que aumentan o disminuyen los momios con respecto a la unidad como base. Si exponenciamos a ambos lados de nuestra ecuaci√≥n:\n\\[ e^{ln\\frac{p(x=1)}{p(x=0)}}=e^{\\beta_o+\\beta_1x +\\epsilon}\\]\n\\[ \\frac{p(x=1)}{p(x=0)}=e^{\\beta_o+\\beta_1x +\\epsilon}\\] Al exponenciar los coeficientes, tenemos los resultados en t√©rminos de momios.\n\\[ \\frac{p}{1-p}=e^{\\beta_o}*+*e^{\\beta_1x}*e^{\\epsilon}\\] Por tantopodemos establecer por cu√°nto se multiplican los momios de probabilidad. Lo cual es una manera m√°s sencilla para interpretar nuestros resultados\n\nexp(coef(modelo0))\n\n(Intercept)   edad_jefe \n 0.03864889  1.00888670 \n\n\nEs muy f√°cil con la librer√≠a jtools, sacar los coeficientes exponenciados. La ventaja es que nos dan tambi√©n los intervalos:\n\nsumm(modelo0, exp=T )\n\n\n\n\n\nObservations\n90093\n\n\nDependent variable\nrecibe_rem\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n\n\n\n\n\nùõò¬≤(1)\n98.97\n\n\nPseudo-R¬≤ (Cragg-Uhler)\n0.00\n\n\nPseudo-R¬≤ (McFadden)\n0.00\n\n\nAIC\n39706.33\n\n\nBIC\n39725.15\n\n\n\n\n\n\n\n\n\nexp(Est.)\n2.5%\n97.5%\nz val.\np\n\n\n\n\n(Intercept)\n0.04\n0.04\n0.04\n-65.98\n0.00\n\n\nedad_jefe\n1.01\n1.01\n1.01\n9.98\n0.00\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.3.4 Agregando una variable\n\nmodelo1&lt;- glm(recibe_rem ~ edad_jefe + sexo_jefe, \n               family = binomial(\"logit\"),\n               data=mydata,\n               na.action=na.exclude)\n\nsummary(modelo1)\n\n\nCall:\nglm(formula = recibe_rem ~ edad_jefe + sexo_jefe, family = binomial(\"logit\"), \n    data = mydata, na.action = na.exclude)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -3.4304208  0.0499645 -68.657  &lt; 2e-16 ***\nedad_jefe       0.0061378  0.0008898   6.898 5.29e-12 ***\nsexo_jefeMujer  0.8042078  0.0288932  27.834  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 39801  on 90092  degrees of freedom\nResidual deviance: 38945  on 90090  degrees of freedom\nAIC: 38951\n\nNumber of Fisher Scoring iterations: 6\n\nconfint(modelo1)\n\nWaiting for profiling to be done...\n\n\n                      2.5 %       97.5 %\n(Intercept)    -3.528639636 -3.332777762\nedad_jefe       0.004392861  0.007881067\nsexo_jefeMujer  0.747572110  0.860837334\n\n\nEste modelo tiene coeficientes que deben leerse ‚Äúcondicionados‚Äù. Es decir, en este caso tenemos que el coeficiente asociado a la edad_jefe, mantiene constante el sexo y viceversa.\nVeamos con los valores exponenciados:\n\nexp(coef(modelo1))\n\n   (Intercept)      edad_jefe sexo_jefeMujer \n    0.03237331     1.00615671     2.23492532"
  },
  {
    "objectID": "P10.html#bondad-de-ajuste",
    "href": "P10.html#bondad-de-ajuste",
    "title": "10¬† Modelos lineales generalizados: Logit",
    "section": "10.4 Bondad de Ajuste",
    "text": "10.4 Bondad de Ajuste\n\n10.4.1 Devianza\nLa devianza es una medida de la bondad de ajuste de los modelos lineales generalizados. O m√°s bien, es una medida de la no-bondad del ajust, puesto que valores m√°s altos indican un peor ajuste.\nR nos da medidas de devianza: la devianza nula y la desviaci√≥n residual. La devianza nula muestra qu√© tan bien la variable de respuesta se predice mediante un modelo que incluye solo la intersecci√≥n (gran media).\n\n\n10.4.2 Prueba de Verosimilitud\n\\[D(y, \\hat{\\mu}) = 2 \\left( \\log \\left( p(y \\mid \\hat{\\theta}_s) \\right) - \\log \\left( p(y \\mid \\hat{\\theta}_0) \\right) \\right) \\]\n¬øC√≥mo saber si ha mejorado nuestro modelo? Podemos hacer un test que compare las devianzas(tendr√≠a la misma l√≥gica que nuestra prueba F del modelo lineal). Para esto tenemos que instalar un paquete ‚Äúlmtest‚Äù\n\nlrtest0&lt;-lmtest::lrtest(modelo0, modelo1)\nlrtest0\n\n\n\n\n#DfLogLikDfChisqPr(&gt;Chisq)\n\n2-1.99e+04¬†¬†¬†¬†¬†¬†¬†¬†\n\n3-1.95e+0417588.56e-167\n\n\n\n\nComo puedes ver, el resultado muestra un valor p muy peque√±o (&lt;.001). Esto significa que agregar el sexo de la jefatura al modelo lleva a un ajuste significativamente mejor sobre el modelo original.\nPodemos seguir a√±adiendo variables s√≥lo ‚Äúsumando‚Äù en la funci√≥n\n\nmodelo2&lt;-glm(recibe_rem ~ edad_jefe + sexo_jefe + tot_integ,\n             family = binomial(\"logit\"), \n             data=mydata, \n             na.action=na.exclude)\n\nsummary(modelo2)\n\n\nCall:\nglm(formula = recibe_rem ~ edad_jefe + sexo_jefe + tot_integ, \n    family = binomial(\"logit\"), data = mydata, na.action = na.exclude)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -3.7274626  0.0618770 -60.240  &lt; 2e-16 ***\nedad_jefe       0.0072699  0.0009066   8.019 1.06e-15 ***\nsexo_jefeMujer  0.8356191  0.0291609  28.655  &lt; 2e-16 ***\ntot_integ       0.0649789  0.0077567   8.377  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 39801  on 90092  degrees of freedom\nResidual deviance: 38877  on 90089  degrees of freedom\nAIC: 38885\n\nNumber of Fisher Scoring iterations: 6\n\n\nY podemos ver si introducir esta variable afect√≥ al ajuste global del modelo\n\nlrtest1&lt;-lrtest(modelo1, modelo2)\nlrtest1\n\n\n\n\n#DfLogLikDfChisqPr(&gt;Chisq)\n\n3-1.95e+04¬†¬†¬†¬†¬†¬†¬†¬†¬†\n\n4-1.94e+04167.61.97e-16\n\n\n\n\n\n\n10.4.3 Test Hosmer-Lemeshow Goodness of Fit ‚ÄúGOF‚Äù\nEl teste Homer-Lemeshow se calcula sobre los datos una vez que las observaciones se han segmentado en grupos basados en probabilidades predichas similares. Este teste examina si las proporciones observadas de eventos son similares a las probabilidades predichas de ocurrencia en subgrupos del conjunto de datos, y lo hace con una prueba de chi cuadrado de Pearson.\n¬°Ojo! No queremos rechazar la hip√≥tesis nula. La hip√≥tesis nula sostiene que el modelo se ajusta a los datos por lo tanto no queremos rechazarla.\n\nhoslem.test(mydata$recibe_rem, fitted(modelo2))\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  mydata$recibe_rem, fitted(modelo2)\nX-squared = 382.48, df = 8, p-value &lt; 2.2e-16\n\n\nNo obstante, esta prueba ha sido criticada. Checa la postura de Paul Allison https://statisticalhorizons.com/hosmer-lemeshow\nEs un problema que tenemos en muestras grandes. Casi siempre preferimos el enfoque de la devianza."
  },
  {
    "objectID": "P10.html#tabla-de-modelos-estimados",
    "href": "P10.html#tabla-de-modelos-estimados",
    "title": "10¬† Modelos lineales generalizados: Logit",
    "section": "10.5 Tabla de modelos estimados",
    "text": "10.5 Tabla de modelos estimados\n\n#stargazer(modelo0, modelo1,modelo2, type = 'latex', header=FALSE)\n\n\nstargazer(modelo0, modelo1,modelo2, \n          type = 'text', header=FALSE)\n\n\n=====================================================\n                          Dependent variable:        \n                  -----------------------------------\n                              recibe_rem             \n                      (1)         (2)         (3)    \n-----------------------------------------------------\nedad_jefe          0.009***    0.006***    0.007***  \n                    (0.001)     (0.001)     (0.001)  \n                                                     \nsexo_jefeMujer                 0.804***    0.836***  \n                                (0.029)     (0.029)  \n                                                     \ntot_integ                                  0.065***  \n                                            (0.008)  \n                                                     \nConstant           -3.253***   -3.430***   -3.727*** \n                    (0.049)     (0.050)     (0.062)  \n                                                     \n-----------------------------------------------------\nObservations        90,093      90,093      90,093   \nLog Likelihood    -19,851.170 -19,472.330 -19,438.510\nAkaike Inf. Crit. 39,706.330  38,950.650  38,885.020 \n=====================================================\nNote:                     *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nPara sacar los coeficientes exponenciados\n\nstargazer(modelo0, modelo1,modelo2, \n          type = 'text', header=FALSE,\n          apply.coef = exp,\n          apply.se   = exp)\n\n\n=====================================================\n                          Dependent variable:        \n                  -----------------------------------\n                              recibe_rem             \n                      (1)         (2)         (3)    \n-----------------------------------------------------\nedad_jefe            1.009       1.006       1.007   \n                    (1.001)     (1.001)     (1.001)  \n                                                     \nsexo_jefeMujer                  2.235**     2.306**  \n                                (1.029)     (1.030)  \n                                                     \ntot_integ                                    1.067   \n                                            (1.008)  \n                                                     \nConstant             0.039       0.032       0.024   \n                    (1.051)     (1.051)     (1.064)  \n                                                     \n-----------------------------------------------------\nObservations        90,093      90,093      90,093   \nLog Likelihood    -19,851.170 -19,472.330 -19,438.510\nAkaike Inf. Crit. 39,706.330  38,950.650  38,885.020 \n=====================================================\nNote:                     *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nVeamos con jtools:\n\nexport_summs(modelo0, modelo1,modelo2, exp=T)\n\n\n\n\nModel 1Model 2Model 3\n\n(Intercept)0.04 ***0.03 ***0.02 ***\n\n(0.05)¬†¬†¬†(0.05)¬†¬†¬†(0.06)¬†¬†¬†\n\nedad_jefe1.01 ***1.01 ***1.01 ***\n\n(0.00)¬†¬†¬†(0.00)¬†¬†¬†(0.00)¬†¬†¬†\n\nsexo_jefeMujer¬†¬†¬†¬†¬†¬†¬†2.23 ***2.31 ***\n\n¬†¬†¬†¬†¬†¬†¬†(0.03)¬†¬†¬†(0.03)¬†¬†¬†\n\ntot_integ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†1.07 ***\n\n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†(0.01)¬†¬†¬†\n\nN90093¬†¬†¬†¬†¬†¬†¬†90093¬†¬†¬†¬†¬†¬†¬†90093¬†¬†¬†¬†¬†¬†¬†\n\nAIC39706.33¬†¬†¬†¬†38950.65¬†¬†¬†¬†38885.02¬†¬†¬†¬†\n\nBIC39725.15¬†¬†¬†¬†38978.88¬†¬†¬†¬†38922.65¬†¬†¬†¬†\n\nPseudo R20.00¬†¬†¬†¬†0.03¬†¬†¬†¬†0.03¬†¬†¬†¬†\n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nTambi√©n la librer√≠a ‚ÄúsjPlot‚Äù tiene el comando ‚Äúplot_model()‚Äù\n\nplot_model(modelo2)\n\nProfiled confidence intervals may take longer time to compute.\n  Use `ci_method=\"wald\"` for faster computation of CIs.\n\n\n\n\n\nPor default nos da los coeficientes exponenciados.\n¬øC√≥mo saber lo que tiene esos gr√°ficos? Es bueno guardar siempre estos resultados en un objeto. Este objeto es una lista de dos listas\n\nget&lt;-plot_model(modelo2)\n\nProfiled confidence intervals may take longer time to compute.\n  Use `ci_method=\"wald\"` for faster computation of CIs.\n\nget$data\n\n\n\n\ntermestimatestd.errorconf.levelconf.lowconf.highstatisticdf.errorp.valuep.starsp.labelgroupxposxminxmax\n\nedad_jefe1.010.0009070.951.011.018.02Inf1.06e-15¬†***1.01 ***pos32.83¬†3.17\n\nsexo_jefeMujer2.310.0292¬†¬†0.952.182.4428.7¬†Inf1.37e-180***2.31 ***pos21.82¬†2.17\n\ntot_integ1.070.00776¬†0.951.051.088.38Inf5.42e-17¬†***1.07 ***pos10.8251.18\n\n\n\n\n\nplot_model(modelo2, terms= c(\"edad_jefe\", \"sexo_jefe\"), type=\"pred\")\n\nData were 'prettified'. Consider using `terms=\"edad_jefe [all]\"` to get\n  smooth plots.\n\n\n\n\n\nPara poner m√°s de un modelo:\n\nplot_models(modelo1, modelo2) + ggtitle(\"P(recibe remesa)\")"
  },
  {
    "objectID": "P10.html#regresi√≥n-probit",
    "href": "P10.html#regresi√≥n-probit",
    "title": "10¬† Modelos lineales generalizados: Logit",
    "section": "10.6 Regresi√≥n Probit",
    "text": "10.6 Regresi√≥n Probit\n\n10.6.1 Un solo predictor\n\nmprobit&lt;- glm(recibe_rem ~ edad_jefe, \n               family = binomial(\"probit\"), \n               data=mydata,\n               na.action=na.exclude)\nsummary(mprobit)\n\n\nCall:\nglm(formula = recibe_rem ~ edad_jefe, family = binomial(\"probit\"), \n    data = mydata, na.action = na.exclude)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.7852701  0.0230511 -77.448   &lt;2e-16 ***\nedad_jefe    0.0040694  0.0004196   9.699   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 39801  on 90092  degrees of freedom\nResidual deviance: 39705  on 90091  degrees of freedom\nAIC: 39709\n\nNumber of Fisher Scoring iterations: 5\n\n\nComparando probit con logit:\n\njtools::export_summs(modelo0, mprobit)\n\n\n\n\nModel 1Model 2\n\n(Intercept)-3.25 ***-1.79 ***\n\n(0.05)¬†¬†¬†(0.02)¬†¬†¬†\n\nedad_jefe0.01 ***0.00 ***\n\n(0.00)¬†¬†¬†(0.00)¬†¬†¬†\n\nN90093¬†¬†¬†¬†¬†¬†¬†90093¬†¬†¬†¬†¬†¬†¬†\n\nAIC39706.33¬†¬†¬†¬†39708.89¬†¬†¬†¬†\n\nBIC39725.15¬†¬†¬†¬†39727.70¬†¬†¬†¬†\n\nPseudo R20.00¬†¬†¬†¬†0.00¬†¬†¬†¬†\n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\n¬øCu√°l es la diferencia?\nhttps://tutorials.methodsconsultants.com/posts/what-is-the-difference-between-logit-and-probit-models.\nY Allison:\nhttps://statisticalhorizons.com/in-defense-of-logit-part-1 https://statisticalhorizons.com/in-defense-of-logit-part-2"
  }
]